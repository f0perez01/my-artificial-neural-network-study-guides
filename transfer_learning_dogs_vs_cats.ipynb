{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# transfer_learning_dogs_vs_cats\n",
        "\n",
        "El script tiene como objetivo principal demostrar cómo aplicar transfer learning y fine-tuning usando un modelo preentrenado (Xception, entrenado en ImageNet) para realizar la clasificación binaria de imágenes (perros vs gatos), utilizando TensorFlow/Keras.\n",
        "\n",
        "En detalle, los objetivos del script son:\n",
        "\n",
        "1. Preparar el dataset:\n",
        "\n",
        "  * Descargar el conjunto de datos cats_vs_dogs desde tensorflow_datasets.\n",
        "\n",
        "  * Dividirlo en entrenamiento (40%), validación (10%) y test (10%).\n",
        "\n",
        "  * Redimensionar todas las imágenes a 150x150 píxeles y normalizarlas a un rango [-1,1].\n",
        "\n",
        "  * Crear pipelines eficientes con cache(), batch() y prefetch().\n",
        "\n",
        "2. Aumentar los datos (data augmentation):\n",
        "\n",
        "  * Aplicar transformaciones aleatorias (flip horizontal y rotación) para incrementar artificialmente el tamaño y variabilidad del dataset.\n",
        "\n",
        "3. Construir el modelo:\n",
        "\n",
        "  * Cargar Xception preentrenado en ImageNet como extractor de características (con trainable=False).\n",
        "\n",
        "  * Agregar un bloque de clasificación con GlobalAveragePooling2D, Dropout y una capa densa final para salida binaria.\n",
        "\n",
        "  * Integrar directamente la normalización y el aumento de datos como parte del modelo.\n",
        "\n",
        "4. Entrenar el modelo (fase de transferencia):\n",
        "\n",
        "  * Entrenar únicamente las capas del nuevo clasificador manteniendo congelado el modelo base.\n",
        "\n",
        "5. Realizar fine-tuning:\n",
        "\n",
        "  * Descongelar el modelo base (trainable=True) y entrenar con una tasa de aprendizaje muy baja para ajustar finamente los pesos.\n",
        "\n",
        "6. Evaluar y predecir:\n",
        "\n",
        "  * Realizar predicciones sobre batches de imágenes del conjunto de test.\n",
        "\n",
        "  * Mostrar cómo hacer predicciones sobre imágenes individuales o datos externos (imágenes sueltas cargadas manualmente).\n",
        "\n",
        "### En resumen:\n",
        "\n",
        "El script enseña el flujo completo para aplicar transferencia de aprendizaje con un modelo preentrenado en Keras, adaptarlo a un problema nuevo (clasificación de perros y gatos), mejorar su desempeño con fine-tuning y usarlo para predicciones en distintos formatos de entrada."
      ],
      "metadata": {
        "id": "M1qW3Yj2Ws-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning y fine-tuning\n",
        "\n",
        "En este ejemplo utilizaremos modelos preentrenado en Keras para hacer transferencia de aprendizaje desde ImageNet a un set de datos de clasificación de perros y gatos."
      ],
      "metadata": {
        "id": "uuajyx20Vgyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMk9pCOVgXC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtención de los datos\n",
        "\n",
        "Para mantener el set de datos pequeño y no caer en sobreentrenamiento, usaremos el 40% de este para entrenamiento (25.000 imágenes), 10% para validaciónn, y 10% para test (no consideren los errores en la descarga, no son un problema)."
      ],
      "metadata": {
        "id": "S_Sj7iQDVlfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
        "    as_supervised=True,  # para incluir las etiquetas\n",
        ")\n",
        "\n",
        "print(f\"Ejemplos entrenamiento: {tf.data.experimental.cardinality(train_ds)}\")\n",
        "print(f\"Ejemplos validación: {tf.data.experimental.cardinality(validation_ds)}\")\n",
        "print(f\"Ejemplos test: {tf.data.experimental.cardinality(test_ds)}\")"
      ],
      "metadata": {
        "id": "y176XxkDVjkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(train_ds.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(int(label))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "l7xG3QioVmUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalización de los datos\n",
        "\n",
        "Las imágenes de este conjunto de datos tienen distintos tamaños. Para corregir esto y normalizar los datos, llevaremos cada imagen a una resolución de 150x150 pixeles, y transformaremos el valor de color (R, G y B) de cada pixel del intervalo [0,255] al [-1,1]. Para hacer esto último, utilizaremos una capa de tipo `Normalization` en la red, que aplica una transformación fija a cada dato de entrada."
      ],
      "metadata": {
        "id": "YMZGBMXUVpeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# la capa de normalización ejecuta outputs = (inputs - mean) / sqrt(var)\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "norm_layer = keras.layers.Normalization(mean=mean, variance=var)"
      ],
      "metadata": {
        "id": "OcL58UjuVrDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, hacemos el _resizing_:"
      ],
      "metadata": {
        "id": "-bHTIbT3VtmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = (150, 150)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
      ],
      "metadata": {
        "id": "clV7mRltVvEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como extra opcional, pero muy práctico, agregamos un mecanismo de `caching` para acelerar la carga de datos."
      ],
      "metadata": {
        "id": "75WrLAsrVu6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds_batched = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "validation_ds_batched = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "test_ds_batched = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "mAs4EzRXVyFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aumento de datos\n",
        "\n",
        "Dado que el conjunto de datos es pequeño para el tamaño de una red, utilizaremos un esquema de aumento de datos para incrementar artificialmente la cantidad de esto. En este caso en particular, aplicaremos a cada dato de manera aleatoria, al momento de ser ingresado a la red, un flip horizontal y una rotación. Al igual que antes, esta transformación la modelaremos como capas, de forma de embeberla directamente en la estructura."
      ],
      "metadata": {
        "id": "kKMNeRPqVzhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.RandomFlip(\"horizontal\"),\n",
        "        keras.layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "pel3xs5eV1aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualicemos algunas transformaciones:"
      ],
      "metadata": {
        "id": "iAoZDalaV2vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_ds_batched.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = images[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(\n",
        "            tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "rj--PZu6V21b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción del modelo\n",
        "\n",
        "Ahora cargaremos un modelo desde Keras (Xception), que fue entrenado originalmente en ImageNet. Para hacer la transferencia, incluimos el aumento de datos, la normalización y finalmente un grupo de capas para hacer la clasificación en el nuevo set de datos (pooling, dropout, capa densa).\n",
        "\n",
        "Para que todo esto funcione en modo de transferencia, es fundamental setear el modelo importado con `trainable=False`, de forma que sea utilizado como un extractor de características y que lo único que se entrene sean las capas del nuevo clasificador."
      ],
      "metadata": {
        "id": "sPUIG9mzV7J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.Xception(weights=\"imagenet\",\n",
        "                                         input_shape=(150, 150, 3),\n",
        "                                         #no incluimos el clasificador\n",
        "                                         include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = norm_layer(x)\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WgQ31Xm0V5gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del modelo (solo capas de clasificación)"
      ],
      "metadata": {
        "id": "K2DFzRKxV9so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "model.fit(train_ds_batched, epochs=epochs, validation_data=validation_ds_batched)"
      ],
      "metadata": {
        "id": "1jd4pKA_V91w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Finalmente, haremos un par de _epochs_ de fine-tuning, cuidando setear el modelo ahora en `trainable=True`. Otro aspecto relevante es el learning rate, que es mantenido en un valor bajo para evitar el sobrenetrenamiento."
      ],
      "metadata": {
        "id": "qRJvU5zkWA9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # learning rate bajo\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 5\n",
        "model.fit(train_ds_batched, epochs=epochs, validation_data=validation_ds_batched)"
      ],
      "metadata": {
        "id": "puQ671hDWCqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien la mejor en rendimiento no es increíble, esta sí es medible. Es importante notar como se reduce rapidamente el valor de la pérdida, lo que indica un alto riesgo de sobreentrenamiento si se continua con el proceso por más _epochs_."
      ],
      "metadata": {
        "id": "cP7ZA3H_WFEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción\n",
        "Existen múltiples formas de hacer predicción utilizando un modelo ya entrenado. Algo que siempre es fundamental es asegurarse que los datos de entrada estén en el formato adecuado. En este caso, que las imágenes tenga la dimensión correcta.\n",
        "\n",
        "### Predicción en base a batches\n",
        "Si queremos hacer predicción sobre los ejemplos de test del set de datos con que entrenamos, basta con pedirle a `test_ds_batched` un batch (32 elementos) y luego aplicar la función `predict`."
      ],
      "metadata": {
        "id": "BVtnOPq2WIjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = test_ds_batched.take(1)\n",
        "prediction = model.predict(batch) > 0"
      ],
      "metadata": {
        "id": "s9FUnDK6WGcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images in batch:\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  for i in range(batch_size):\n",
        "      ax = plt.subplot(4, 8, i + 1)\n",
        "      plt.imshow(images[0][i].numpy().astype(\"int32\"))\n",
        "      plt.title(int(prediction[i]))\n",
        "      plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "WqYg3UcPWQic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción sobre ejemplos que no están en un batch\n",
        "Muchas veces, los ejemplos no se encontrarán organizados en batches, ya sea porque no han sido procesados para que tengan ese formato, a pesar de pertenecer al mismo conjunto de datos que el usado para entrenar, o porque vienen de otra fuente. Cualquiera sea el caso, a pesar de que el modelo esté compilado para batches de un tamaño, igualmente podrá predecir sobre un conjunto de menor o mayor tamaño."
      ],
      "metadata": {
        "id": "7OaNdBUtWTB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = test_ds.take(9)\n",
        "prediction = model.predict(images) > 0"
      ],
      "metadata": {
        "id": "qtXR--61WVZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "images_list = []\n",
        "labels_list = []\n",
        "\n",
        "for batch_images, batch_labels in test_ds:\n",
        "    # Si el batch es de una sola imagen, expandir dimensión:\n",
        "    if len(batch_images.shape) == 3:\n",
        "        images_list.append(batch_images.numpy())\n",
        "        labels_list.append(batch_labels.numpy())\n",
        "    else:\n",
        "        images_list.extend(batch_images.numpy())\n",
        "        labels_list.extend(batch_labels.numpy())\n",
        "\n",
        "    if len(images_list) >= 9:\n",
        "        break\n",
        "\n",
        "# Tomar exactamente 9 imágenes y etiquetas\n",
        "images = np.stack(images_list[:9])\n",
        "labels = np.array(labels_list[:9])\n",
        "\n",
        "# Realizar la predicción\n",
        "predictions = model.predict(images) > 0\n"
      ],
      "metadata": {
        "id": "IbSDy7vMWXL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, img in enumerate(images):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img.astype(\"int32\"))\n",
        "    plt.title(int(predictions[i]))  # Asegúrate de que predictions está alineado con images\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "KGtUA0cLWZTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto funciona incluso para ejemplos sueltos subidos a colab."
      ],
      "metadata": {
        "id": "IbvtLMcFWa8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.keras.utils.load_img('supuestamente_un_perro.jpg')\n",
        "img = tf.keras.utils.img_to_array(img)\n",
        "plt.figure(figsize=(10, 10))\n",
        "ax = plt.imshow(img.astype(\"int32\"))"
      ],
      "metadata": {
        "id": "4tpVYYiaWbDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.image.resize(img, size)\n",
        "plt.figure(figsize=(10, 10))\n",
        "ax = plt.imshow(img.numpy().astype(\"int32\"))"
      ],
      "metadata": {
        "id": "GGqPCG2rWeQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(tf.expand_dims(img, 0)) > 0"
      ],
      "metadata": {
        "id": "l1A-NZEnWgrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img.numpy().astype(\"int32\"))\n",
        "ax = plt.title(int(prediction))"
      ],
      "metadata": {
        "id": "J64YFyqiWh6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}