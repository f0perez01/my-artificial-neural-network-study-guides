{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# mlp_autoencoder_cifar10_fashionmnist\n",
        "\n",
        "El script tiene dos objetivos principales claramente diferenciados:\n",
        "\n",
        "---\n",
        "\n",
        "1. **Entrenamiento de un MLP para clasificación de imágenes (CIFAR-10)**\n",
        "\n",
        "  * Construir un perceptrón multicapa (MLP) en Keras para clasificar imágenes del dataset CIFAR-10.\n",
        "\n",
        "  * Preprocesar los datos (normalización y visualización inicial).\n",
        "\n",
        "  * Entrenar el modelo, probando diferentes hiperparámetros y arquitecturas (capas y neuronas) para mejorar el rendimiento en el conjunto de validación/test.\n",
        "\n",
        "  * Medir y reportar métricas clave:\n",
        "\n",
        "    * Pérdida y exactitud en entrenamiento y validación.\n",
        "\n",
        "    * Velocidad por época.\n",
        "\n",
        "  * Graficar la evolución de pérdida y exactitud durante el entrenamiento.\n",
        "\n",
        "2. **Construcción y análisis de autoencoders (Fashion-MNIST)**\n",
        "\n",
        "  * Construir autoencoders en Keras con distintas dimensiones del \"código\" (representación comprimida): 16, 32 y 64.\n",
        "\n",
        "  * Entrenar los modelos para minimizar la pérdida de reconstrucción.\n",
        "\n",
        "  * Comparar el desempeño entre entrenamiento y validación/test según el tamaño de la representación.\n",
        "\n",
        "  * Visualizar resultados:\n",
        "\n",
        "    * Imágenes originales vs reconstruidas.\n",
        "\n",
        "    * Evolución de la pérdida por época.\n",
        "\n",
        "    * Relación entre el tamaño del código y la pérdida promedio de reconstrucción.\n",
        "\n",
        "---\n",
        "\n",
        "En resumen, el script busca enseñar y comparar dos aplicaciones diferentes de redes neuronales:\n",
        "\n",
        "1. Clasificación supervisada (MLP en CIFAR-10).\n",
        "\n",
        "2. Aprendizaje no supervisado mediante autoencoders (compresión y reconstrucción en Fashion-MNIST)."
      ],
      "metadata": {
        "id": "vseIKt9gsZZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: MLP con imágenes\n",
        "\n",
        "•Implemente en Keras un MLP con la cantidad de capas y neuronas que prefiera, que permita hacer clasificación de imágenes.\n",
        "\n",
        "•Entrene la red en CIFAR10 y reporte valores relevantes: velocidad por época, pérdida entrenamiento, pérdida validación, etc.\n",
        "\n",
        "•Juegue con los hiperparámetros y estructura de la red hasta obtener el rendimiento más alta en el set de validación/test."
      ],
      "metadata": {
        "id": "ZHQJo3l3qodG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lk8eJYdohEv"
      },
      "outputs": [],
      "source": [
        "# librerias clasicas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#libreria sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del dataset CIFAR-10"
      ],
      "metadata": {
        "id": "-rQyg99Oqrfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "h31UdkmOqO9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r6evFH9RqQUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción del modelo MLP"
      ],
      "metadata": {
        "id": "xygPmAXgqubM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32 ,32, 3) # Imagenes de 32 x 32 con 3 canales"
      ],
      "metadata": {
        "id": "Nv-2JnNMqSFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.InputLayer(input_shape= input_shape))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2j_MK_oVqTVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "ECZ-Gqc7qyYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "iYPjyldMqVYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "id": "yL48T4MNqWm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from_logits = TRUE --> Internamente usa softmax"
      ],
      "metadata": {
        "id": "IiHmqFJkq1tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=128, epochs=50, validation_split=0.1)"
      ],
      "metadata": {
        "id": "x-tlDFsZqYqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación"
      ],
      "metadata": {
        "id": "OWjoL6lcq59A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_images, test_labels, verbose = 0)\n",
        "print(\"Loss en conjunto de test:\",round(score[0],3))\n",
        "print(\"Accuracy en conjunto de test:\", round(score[1],3))"
      ],
      "metadata": {
        "id": "OcVxRZgpqbBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rporte de valores relevantes y gráficos"
      ],
      "metadata": {
        "id": "kf_I0j9Pq-Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "QGUvuDNiqcQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ],
      "metadata": {
        "id": "Bpt1DMHkrA2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "b5-9ZKpmqePM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 2: autoencoder\n",
        "\n",
        "Un autoencoder es una arquitectura de red neuronal que se utiliza para aprender features generativas, es decir, que permitan generar datos.\n",
        "En particular, un autoencoder utiliza un estructura de cuello de botella para generar un output que sea lo más parecido posible al input.\n",
        "\n",
        "•Utilizando Keras, construya y entrene autoencoders para alguno de los sets de datos disponibles.\n",
        "\n",
        "•Haga un análisis de sensibilidad para el código (code en la figura), graficando su tamaño vs la pérdida de reconstrucción promedio. Compare estos valores para los sets de entrenamiento y validación/test.\n"
      ],
      "metadata": {
        "id": "l2uehaeiqjSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de datos"
      ],
      "metadata": {
        "id": "mJ4UZUMxrNPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "M2vzoqZGrMv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "LNv-JcwYrSgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uSHZwg44rT2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción del modelo"
      ],
      "metadata": {
        "id": "d1Og8CPDrQ-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_autoencoder(input_shape, representation_size):\n",
        "    encoder = models.Sequential()\n",
        "    encoder.add(layers.InputLayer(input_shape=input_shape))\n",
        "    encoder.add(layers.Flatten())\n",
        "    encoder.add(layers.Dense(256, activation='relu'))\n",
        "    encoder.add(layers.Dense(128, activation='relu'))\n",
        "    encoder.add(layers.Dense(representation_size, activation='relu'))\n",
        "\n",
        "    decoder = models.Sequential()\n",
        "    decoder.add(layers.Dense(128, activation='sigmoid'))\n",
        "    decoder.add(layers.Dense(256, activation='sigmoid'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(input_shape)) # \"Unflatten\"\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "    model.add(encoder)\n",
        "    model.add(decoder)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "P9A2c-mcrYcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]"
      ],
      "metadata": {
        "id": "99AzRaebraVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representación de tamaño 16"
      ],
      "metadata": {
        "id": "x71VOkHarckg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model16, encoder, decoder = build_autoencoder(input_shape, 16)"
      ],
      "metadata": {
        "id": "6dq2xUrMregy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model16.summary(expand_nested=True)"
      ],
      "metadata": {
        "id": "I6uvNnXMrfwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model16.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history16 = model16.fit(x_train, x_train, batch_size=128, epochs=50, shuffle=True, validation_split=0.1)"
      ],
      "metadata": {
        "id": "UeUFwNyJrhve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history16.history['loss'], label='loss')\n",
        "plt.plot(history16.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwT6G5sWrj5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = model16(x_test[:10])"
      ],
      "metadata": {
        "id": "KRekteCIrluV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(\"Original\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    plt.title(\"Reconstructed\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BsgNjYx5rmwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representación de tamaño 32"
      ],
      "metadata": {
        "id": "YXti-zaurohD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model32, encoder, decoder = build_autoencoder(input_shape, 32)"
      ],
      "metadata": {
        "id": "DlkpUxvIrqDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model32.summary(expand_nested=True)"
      ],
      "metadata": {
        "id": "R0_1v-NQrry9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model32.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history32 = model32.fit(x_train, x_train, batch_size=128, epochs=50, shuffle=True, validation_split=0.1)"
      ],
      "metadata": {
        "id": "Q3q1dYk3rtxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history32.history['loss'], label='loss')\n",
        "plt.plot(history32.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MNxxQ2marvha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = model32(x_test[:10])"
      ],
      "metadata": {
        "id": "bm1DMXjxrw_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(\"Original\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    plt.title(\"Reconstructed\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ovd3tYx7ryHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representación de tamaño 64"
      ],
      "metadata": {
        "id": "VyRn6nv_rzzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model64, encoder, decoder = build_autoencoder(input_shape, 64)"
      ],
      "metadata": {
        "id": "ucoYSceWr0_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model64.summary(expand_nested=True)"
      ],
      "metadata": {
        "id": "OUaZG_xVr2Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model64.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history64 = model64.fit(x_train, x_train, batch_size=128, epochs=50, shuffle=True, validation_split=0.1)"
      ],
      "metadata": {
        "id": "GgdYfb6kr3dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history64.history['loss'], label='loss')\n",
        "plt.plot(history64.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kS-1aK6ir5Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = model64(x_test[:10])"
      ],
      "metadata": {
        "id": "UlbR9B5fr6wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(\"Original\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    plt.title(\"Reconstructed\", fontsize=12)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "afe_O9zRr7yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score16 = model16.evaluate(x_train, x_train, verbose = 0)\n",
        "test_score16 = model16.evaluate(x_test, x_test, verbose = 0)\n",
        "\n",
        "train_score32 = model32.evaluate(x_train, x_train, verbose = 0)\n",
        "test_score32 = model32.evaluate(x_test, x_test, verbose = 0)\n",
        "\n",
        "train_score64 = model64.evaluate(x_train, x_train, verbose = 0)\n",
        "test_score64 = model64.evaluate(x_test, x_test, verbose = 0)"
      ],
      "metadata": {
        "id": "M2r2jRfTr9jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [16, 32, 64]\n",
        "plt.plot(sizes, [train_score16, train_score32, train_score64], label=\"Train Mean Loss\")\n",
        "plt.plot(sizes, [test_score16, test_score32, test_score64], label=\"Test Mean Loss\")\n",
        "plt.xlabel(\"Representation size\")\n",
        "plt.xticks([16, 32, 64])\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "fTfM-2LMr-12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}